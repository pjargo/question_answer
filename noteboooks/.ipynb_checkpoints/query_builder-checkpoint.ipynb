{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e220f807-1a2c-4680-a58a-7b65c2adfa0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp38-none-macosx_10_9_x86_64.whl (143.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp38-cp38-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp38-cp38-macosx_10_9_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch)\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: numpy in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Obtaining dependency information for pillow!=8.3.*,>=5.3.0 from https://files.pythonhosted.org/packages/5a/29/aa1678cae507a480a6d75453c1de98940e5eb6bd8f0e8e8347ec29a4dfc0/Pillow-10.0.0-cp38-cp38-macosx_10_10_x86_64.whl.metadata\n",
      "  Downloading Pillow-10.0.0-cp38-cp38-macosx_10_10_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.0.0-cp38-cp38-macosx_10_10_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, pillow, networkx, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 pillow-10.0.0 sympy-1.12 torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1ff252-c3ab-413b-ae16-139912919800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterargo/anaconda3/envs/myenv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import nltk\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "from utils import get_sha256, clean_text, remove_non_word_chars, clean_text, tokens_to_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af33402-81aa-41d6-b2e0-27975ac5ac9b",
   "metadata": {},
   "source": [
    "#### Prompt user for query\n",
    "- Specify the tokenizer, consistant with Q&A model and parsed pdfs\n",
    "- Prompt user for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246afd8f-cf09-44c6-9bd7-7481e1540044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer for your specific BERT model variant\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6c7669-1ce2-4884-a11e-b6b89032cf5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  What is a contact manifold?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized query:\n",
      " ['what', 'is', 'a', 'contact', 'manifold', '?', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
      "\n",
      "Tokenized query for seach:\n",
      " ['what', 'is', 'a', 'contact', 'manifold'] \n",
      "\n",
      "Tokenized query for seach less stop words:\n",
      " ['contact', 'manifold'] \n",
      "\n",
      "Input IDs query:\n",
      " tensor([[ 2054,  2003,  1037,  3967, 19726,  1029,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]) \n",
      "\n",
      "Attention mask query:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user for an input query\n",
    "user_query = input(\"Enter your query: \")\n",
    "\n",
    "# clean query for BERT input\n",
    "user_query = clean_text(user_query)\n",
    "\n",
    "# clean query for candidate search\n",
    "user_query_for_search = remove_non_word_chars(user_query)\n",
    "\n",
    "# Tokenize the query for BERT input\n",
    "tokenized_query = tokenizer.tokenize(user_query)\n",
    "\n",
    "# Tokenize the query for candidate search\n",
    "tokenized_query_for_search = tokenizer.tokenize(user_query_for_search)\n",
    "\n",
    "# Remove the stop words for the tokenized query for search\n",
    "nltk_stop_words = nltk.corpus.stopwords.words('english')\n",
    "# nltk_stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'table', 'figure', 'arxiv', 'sin', 'cos', 'tan', 'log', 'fx', 'ft', 'dx', 'dt', 'xt'])\n",
    "tokenized_query_for_search_less_sw = [token for token in tokenized_query_for_search if token not in nltk_stop_words]\n",
    "\n",
    "# Pad or truncate the query to a fixed length of 20 tokens (BERT input)\n",
    "max_query_length = 20\n",
    "if len(tokenized_query) > max_query_length:\n",
    "    tokenized_query = tokenized_query[:max_query_length]\n",
    "else:\n",
    "    padding_length = max_query_length - len(tokenized_query)\n",
    "    tokenized_query = tokenized_query + [tokenizer.pad_token] * padding_length\n",
    "\n",
    "# Convert the tokenized query to input IDs and attention mask\n",
    "input_ids_query = tokenizer.convert_tokens_to_ids(tokenized_query)\n",
    "attention_mask_query = [1] * len(input_ids_query)\n",
    "\n",
    "# Convert to tensors\n",
    "input_ids_query = torch.tensor(input_ids_query).unsqueeze(0)  # Add batch dimension\n",
    "attention_mask_query = torch.tensor(attention_mask_query).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "print(\"Tokenized query:\\n\", tokenized_query, \"\\n\")\n",
    "print(\"Tokenized query for seach:\\n\", tokenized_query_for_search, \"\\n\")\n",
    "print(\"Tokenized query for seach less stop words:\\n\", tokenized_query_for_search_less_sw, \"\\n\")\n",
    "print(\"Input IDs query:\\n\", input_ids_query, \"\\n\")\n",
    "print(\"Attention mask query:\\n\", attention_mask_query, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce0bdf-7a2d-4cdc-90b0-be9513da32b1",
   "metadata": {},
   "source": [
    "##### Add the embeddings\n",
    "- Specify the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e01267-a1c9-4320-b422-6679073328b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your trained Word2Vec model\n",
    "model_fname = os.path.join(\"..\", \"models\", \"word_embeddings\", \"word2vec_model.bin\")\n",
    "model = Word2Vec.load(model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25a49f57-9661-4f92-9915-401897e35a11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\t\t\tTokens Length\t\tEmbeddings Shape\n",
      "\t\t\t   Query embeddings:\t      20\t\t     (20, 100)\n",
      "\t\tQuery embeddings for search:\t      5\t\t\t     (5, 100)\n",
      " Query embeddings for search less stopwords:\t      2\t\t\t     (2, 100)\n"
     ]
    }
   ],
   "source": [
    "# Get the query embeddings for the candidate document search\n",
    "query_embeddings = tokens_to_embeddings(tokenized_query, model, RANDOM=False)\n",
    "query_embeddings_search = tokens_to_embeddings(tokenized_query_for_search, model, RANDOM=False)\n",
    "query_embeddings_less_sw = tokens_to_embeddings(tokenized_query_for_search_less_sw, model, RANDOM=False)\n",
    "\n",
    "print(\"\\t\\t\\t\\t\\t\\tTokens Length\\t\\tEmbeddings Shape\")\n",
    "print(f\"\\t\\t\\t   Query embeddings:\\t      {len(tokenized_query)}\\t\\t     {query_embeddings.shape}\")\n",
    "print(f\"\\t\\tQuery embeddings for search:\\t      {len(tokenized_query_for_search)}\\t\\t\\t     {query_embeddings_search.shape}\")\n",
    "print(f\" Query embeddings for search less stopwords:\\t      {len(tokenized_query_for_search_less_sw)}\\t\\t\\t     {query_embeddings_less_sw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb34f19-37d2-4a76-a013-b1cbd88da2b5",
   "metadata": {},
   "source": [
    "##### Store the output the the query directory, filename is hash of query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29dd5893-3316-4690-86c8-23267f788b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71f39bd6e1740e98a1137e7410d0bef56c40510fd934b7153c5e48428ccb0993\n",
      "../query/71f39bd6e1740e98a1137e7410d0bef56c40510fd934b7153c5e48428ccb0993.json\n"
     ]
    }
   ],
   "source": [
    "# store the query\n",
    "query_data = {\n",
    "    \"query\": user_query,\n",
    "    \"input_ids_query\":input_ids_query.tolist(),\n",
    "    \"attention_mask_query\": attention_mask_query.tolist(),\n",
    "    \"query_search\":user_query_for_search,\n",
    "    \"tokenized_query\":tokenized_query,\n",
    "    \"tokenized_query_search\":tokenized_query_for_search,\n",
    "    \"tokenized_query_search_less_sw\":tokenized_query_for_search_less_sw,\n",
    "    \"query_embedding\": query_embeddings_search.tolist(), # Just used for the candidate search\n",
    "    \"query_embedding_search\": query_embeddings_search.tolist(), # Just used for the candidate search, cleaned\n",
    "    \"query_embedding_search_less_sw\": query_embeddings_less_sw.tolist() # Just used for the candidate search, cleaned more\n",
    "}\n",
    "\n",
    "json_string = json.dumps(query_data['query'], indent=2)\n",
    "# print(json_string)\n",
    "\n",
    "# Specify the directory path\n",
    "directory_path = os.path.join(\"..\", 'query')\n",
    "\n",
    "# Check if the directory exists, if not create the directory\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "# Generate a UUID\n",
    "# unique_id = uuid.uuid4()\n",
    "unique_id = get_sha256(json_string)\n",
    "print(unique_id)\n",
    "\n",
    "fname = os.path.join(directory_path, str(unique_id)+'.json')\n",
    "print(fname)\n",
    "\n",
    "with open(fname, 'w') as j_file:\n",
    "    json.dump(query_data, j_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c42e9-3116-4978-9226-83fdfef0566d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
